{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue \n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mygrad as mg\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "from mygrad import Tensor\n",
    "from noggin import create_plot\n",
    "from mynn.layers.conv import conv\n",
    "from mynn.layers.dense import dense\n",
    "\n",
    "from mygrad.nnet.initializers import glorot_uniform\n",
    "from mygrad.nnet.activations import relu\n",
    "from mygrad.nnet.layers import max_pool\n",
    "from mygrad.nnet.losses import softmax_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your `Model`-MyNN class for the architecture prescribed above.\n",
    "\n",
    "class Model:\n",
    "    ''' A simple convolutional neural network. '''\n",
    "    def __init__(self, num_input_channels, f1, f2, d1, num_classes):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_input_channels : int\n",
    "            The number of channels for a input datum\n",
    "            \n",
    "        f1 : int\n",
    "            The number of filters in conv-layer 1\n",
    "        \n",
    "        f2 : int\n",
    "            The number of filters in conv-layer 2\n",
    "\n",
    "        d1 : int\n",
    "            The number of neurons in dense-layer 1\n",
    "        \n",
    "        num_classes : int\n",
    "            The number of classes predicted by the model.\n",
    "        \"\"\"\n",
    "        # Initialize your two convolution layers and two dense layers each \n",
    "        # as class attributes using the functions imported from MyNN\n",
    "        #\n",
    "        # We will use `weight_initializer=glorot_uniform` for all 4 layers\n",
    "        \n",
    "        # Note that you will need to compute `input_size` for\n",
    "        # dense layer 1 : the number of elements being produced by the preceding conv\n",
    "        # layer\n",
    "        # <COGINST>\n",
    "        init_kwargs = {'gain': np.sqrt(2)}\n",
    "        self.conv1 = conv(num_input_channels, f1, 5, 5, \n",
    "                          weight_initializer=glorot_uniform, \n",
    "                          weight_kwargs=init_kwargs)\n",
    "        self.conv2 = conv(f1, f2, 5, 5 ,\n",
    "                          weight_initializer=glorot_uniform, \n",
    "                          weight_kwargs=init_kwargs)\n",
    "        self.dense1 = dense(f2 * 5 * 5, d1, \n",
    "                            weight_initializer=glorot_uniform, \n",
    "                            weight_kwargs=init_kwargs)\n",
    "        self.dense2 = dense(d1, num_classes, \n",
    "                            weight_initializer=glorot_uniform, \n",
    "                            weight_kwargs=init_kwargs)\n",
    "        # </COGINST>\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        ''' Defines a forward pass of the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy.ndarray, shape=(N, 1, 32, 32)\n",
    "            The input data, where N is the number of images.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        mygrad.Tensor, shape=(N, num_classes)\n",
    "            The class scores for each of the N images.\n",
    "        '''\n",
    "        \n",
    "        # Define the \"forward pass\" for this model based on the architecture detailed above.\n",
    "        # Note that, to compute \n",
    "        # We know the new dimension given the formula: out_size = ((in_size - filter_size)/stride) + 1\n",
    "    \n",
    "        # <COGINST>\n",
    "        x = relu(self.conv1(x))\n",
    "        x = max_pool(x, (2, 2), 2)\n",
    "        x = relu(self.conv2(x))\n",
    "        x = max_pool(x, (2, 2), 2)\n",
    "        x = relu(self.dense1(x.reshape(x.shape[0], -1)))\n",
    "        return self.dense2(x)\n",
    "        # </COGINST>\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            for param, (name, array) in zip(self.parameters, np.load(f).items()):\n",
    "                param.data[:] = array\n",
    "\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        \"\"\" A convenience function for getting all the parameters of our model. \"\"\"\n",
    "        # Create a list of every parameter contained in the 4 layers you wrote in your __init__ function\n",
    "        # <COGINST>\n",
    "        params = []\n",
    "        for layer in (self.conv1, self.conv2, self.dense1, self.dense2):\n",
    "            params += list(layer.parameters)\n",
    "        return params\n",
    "        # </COGINST>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(f1=20, f2=10, d1=20, num_input_channels=1, num_classes=10)\n",
    "model.load_model(\"handwrite_digit_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floodfill(img, low_cutoff = 0, high_cutoff = 255):\n",
    "    dx = np.array([1,1,1,0,0,-1,-1,-1])\n",
    "    dy = np.array([1,0,-1,1,-1,1,0,-1])\n",
    "    #img should be a np array\n",
    "    (nrows, ncols) = img.shape\n",
    "    binary_img = np.zeros(img.shape)\n",
    "    visited_array = np.zeros(img.shape, dtype = \"bool\")\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            if (img[row,col] >= low_cutoff and img[row,col] <= high_cutoff):\n",
    "                binary_img[row,col] = 1\n",
    "    \n",
    "    bounds = []\n",
    "    for col in range(ncols):\n",
    "        for row in range(nrows):\n",
    "            if (binary_img[row,col] == 0 or visited_array[row,col] == True):\n",
    "                continue\n",
    "            maxrow = -1\n",
    "            maxcol = -1\n",
    "            minrow = 1000000000\n",
    "            mincol = 1000000000\n",
    "            visited_array[row,col] = True\n",
    "            q = Queue()\n",
    "            q.put((row,col))\n",
    "            while (q.qsize() != 0):\n",
    "                cur_loc = q.get()\n",
    "                maxrow = max(maxrow, cur_loc[0])\n",
    "                maxcol = max(maxcol, cur_loc[1])\n",
    "                minrow = min(minrow, cur_loc[0])\n",
    "                mincol = min(mincol, cur_loc[1])\n",
    "                for index in range(8):\n",
    "                    newx = dx[index] + cur_loc[0]\n",
    "                    newy = dy[index] + cur_loc[1]\n",
    "                    if (newx >= 0 and newx < nrows and newy >= 0 and newy < ncols and visited_array[newx, newy] == False and binary_img[newx, newy] == 1):\n",
    "                        visited_array[newx, newy] = True\n",
    "                        q.put((newx, newy))\n",
    "            bounds.append([minrow, maxrow, mincol, maxcol])\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_grayscale(rgb_img):\n",
    "    img = np.einsum(\"...hwc,c->...hw\", rgb_img, [0.2989, 0.5870, 0.1140])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_digits(img_path):\n",
    "    img = plt.imread(img_path)\n",
    "    # print(img.shape)\n",
    "    new_img = rgb_to_grayscale(img)\n",
    "    new_img = new_img.T[...,::-1]\n",
    "    (nrows, ncols) = new_img.shape\n",
    "    if (nrows > 500):\n",
    "        new_img = cv2.resize(new_img, (500, nrows))\n",
    "    (nrow, ncols) = new_img.shape\n",
    "    if (nrows > 500):\n",
    "        new_img = cv2.resize(new_img, (ncols, 500))\n",
    "    #plt.imshow(new_img, cmap = \"gray\")\n",
    "    subimages = floodfill(new_img, high_cutoff=100)\n",
    "    for subimage in subimages:\n",
    "        #print(subimage)\n",
    "        subimage[0] -= 16\n",
    "        subimage[1] += 16\n",
    "        subimage[2] -= 16\n",
    "        subimage[3] += 16\n",
    "    answers = []\n",
    "    for subimage in subimages:\n",
    "        answers.append(new_img[subimage[0]:subimage[1],subimage[2]:subimage[3]])\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-89b266512462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plt.imshow(new_img, cmap = \"gray\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'answers' is not defined"
     ]
    }
   ],
   "source": [
    "# plt.imshow(new_img, cmap = \"gray\")\n",
    "plt.imshow(answers[6], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image(imgs):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "            ----------\n",
    "            imgs : list of arrays\n",
    "                List of arrays of bounded images of digits from detect_digits\n",
    "\n",
    "\n",
    "    Output\n",
    "            ----------\n",
    "            new_imgs : np.array\n",
    "                The (N, 1, 32, 32) of images to go into the model\n",
    "\n",
    "    \"\"\"\n",
    "    N = len(imgs)\n",
    "    convert_imgs = np.empty((N, 1, 32, 32))\n",
    "    for i, j in enumerate(imgs):\n",
    "        #change to 32 x 32\n",
    "        img = cv2.resize(j, (32,32))\n",
    "        #add the 1 at the beginning\n",
    "        img = img[np.newaxis]\n",
    "        convert_imgs[i] = img\n",
    "    \n",
    "    #typecast to float32\n",
    "    convert_imgs = convert_imgs.astype(np.float32)\n",
    "    convert_imgs = 255 - convert_imgs\n",
    "    #normalize all data\n",
    "    convert_imgs /=  255.\n",
    "    return convert_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recog_digits(model, answers):\n",
    "    p = convert_image(answers)\n",
    "    new_p = model(p).data\n",
    "    ID = [np.argmax(row) for row in new_p]\n",
    "    return ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_function(img):\n",
    "    boxes = detect_digits(img)\n",
    "    return recog_digits(model, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Run this to actually comprehend handwritten digits\n",
    "print(master_function(\"Test_Numbers_2.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
